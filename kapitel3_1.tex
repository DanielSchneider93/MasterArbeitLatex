\chapter{Vergleich von Photogrammetrie und SLAM}

Es ist inzwischen allgemein bekannt, dass Photogrammetrie und geometrische Computer Vision, in dessen Bereich SLAM einzuordnen ist, zwei eng zusammenhängende Disziplinen sind. Sie haben viele ähnliche Aufgabenstellungen und Ziele, wie Kalibrierung, Orientierung und Rekonstruktion. Viele Arbeiten und Forschungen beziehen sich auf beide Gebiete, wie relative Orientierung (Philip, 1996; Nistèr, 2004), die räumliche Analyse von Einzelbildern (Masry, 1981; Lepetit et al., 2009), Feature Erkennung  (Förstner \& Gülch, 1986; Lowe, 2004) oder etwa der Bündelblockausgleich  (Triggs et al., 2000). Dabei sollte beachtet werden, dass viele dieser Probleme erst in der Photogrammetrie untersucht und beschrieben worden sind und erst später in der Computer Vision signifikant weiter entwickelt wurden. Dies hat die Kommunikation zwischen beiden Fachbereichen gefördert (vgl. \cite{ph_vs_cv} S.93).


\section{Ähnlichkeiten und Unterschiede zwischen Visual SLAM, Photogrammetrie und SfM}

In den Kapiteln 3 und 4 wurde ein Überblick über die Funktionsweise von Photogrammetrie und Computer Vision, mit Fokus auf SLAM, gegeben. Um einen Gesamtüberblick über diese Themenbereiche geben zu können, sowie die Abgrenzung der Bereiche zu ermöglichen, werden nun die Ähnlichkeiten und Unterschiede der Technologien beschrieben. Der Zusammenhang der Inhalte von Photogrammetrie und SLAM, bezieht sich hauptsächlich auf die Theorie und Anwendung der Zentralprojektion. Die Gemeinsamkeiten der beiden Felder sind Kamera Kalibrierung, Positionsbestimmung der Kamera, Feature Erkennung und Matching, sowie Modellerstellung der Umwelt. Doch warum ist SLAM ein Teil von Computer Vision und nicht nur ein Teilbereich der Photogrammetrie?

Obwohl bemerkenswerte Entwicklungen in beiden Bereichen gemacht wurden, ist das Verhältnis zwischen den beiden Diszipllinen noch sehr distinkt. Die Unterscheidung kann auf die unterschiedlichen Traditionen, Philosophien und Anwendungsbereiche zurückgeführt werden. In der Photogrammetrie, die ihren Ursprung in der Vermessung und Kartierung hat, ist Genauigkeit und Präzision das Hauptaugenmerk und die meisten photogrammetrischen Arbeiten sind im Bereich des Post-Processing anzusiedeln. Für Computer Vision hingegen ist die Genauigkeit eher zweitrangig und wird meist nur durch die Anwendung definiert. Die Verarbeitungsgeschwindigkeit stellt in diesem Bereich jedoch den kritischen Faktor dar, da viele Anwendungen in Echtzeit ablaufen müssen, wie beispielsweise Objekterkennung, Roboternavigation oder Positionsbestimmung im Raum. Auch wenn photogrammetrische Verfahren immer mehr in Echtzeitanwendungen beteiligt sind, sind die beiden Ansätze grundverschieden. Weiterhin ist die Geometrie nach wie vor ein Hauptanliegen der Photogrammetrie, während in der Computer Vision maschinelles Lernen und Erkennung im Vordergrund steht. Aus mathematischer Sicht sind Photogrammetrie und Computer Vision zwei verschiedene Repräsentationen und Lösungen der Kamerageometrie (vgl. \cite{ph_vs_cv} S.93-94).

Doch wie kann man die Gebiete nun voneinander abgrenzen? Alle diese Verfahren beschreiben eigentlich unterschiedliche Ansätze für das gleiche Problem: die gleichzeitige Lokalisierung eines Sensors in Bezug auf seine Umgebung bei gleichzeitiger Erstellung einer 3D-Karte dieser Umgebung. Das einzigartige Merkmal von monokularem \textbf{visuellem SLAM} ist nicht, dass die Kameraposition und Szenenstruktur wiederhergestellt werden, sondern dass der Prozess simultan, rekursiv und in Echtzeit durchgeführt wird. Dies impliziert dynamisches Abtasten, wobei die Karte so aufgebaut sein muss, dass sie im laufenden Prozess die Positionsbestimmung von neu aufgenommenen Bildern integrieren kann, sowie die Triangulation neuer Punkte unterstützt. SLAM Konzepte sind deswegen aus den Bereichen wie der Selbsterkundung von Robotern, der automatischen Fahrzeugnavigation oder im nicht fotografischen geometrischen Kontext, wie etwa dem Handlaser Scanning entstanden und weiterentwickelt worden. Wenn der Echtzeitaspekt von monokularem visuellem SLAM, was auch als visuelle Odometrie bezeichnet werden kann, wegfällt, bleiben SfM und Photogrammerie übrig. \textbf{Structure from Motion} wird als eine der herausragendsten Leistungen der Computer Vision bezeichnet. Es muss jedoch bedacht werden, dass die Entwicklung dieser Feature basierten Matching- und Lokaliserungstechnik von 3D Punkten im Raum wenig mit der Bildbasierten 3D-Messung, das heißt der Photogrammetrie zu tun hatte, sondern mehr mit der räumlichen Archivierung von ungeordneten Sammlungen von Bildern, oft von unbekannten Kameras. \\ Bei SfM wird hauptsächlich die Kameralokalisierung und nicht die Erzeugung von Punktwolken betont und es wurde die Notwendigkeit der Kamerakalibrierung erkannt. Die technischen Prinzipien, welche die Grundlagen der \textbf{Photogrammetrie} bilden, sind bei der Entwicklung von Structure from Motion nicht berücksichtigt. Dazu zählen zum Beispiel geometrisches Netzwerkdesign, metrische Kamerabetrachtung, Genauigkeitsoptimierung und Varianzausbreitung, systematische Fehlerkompensation und grobe Fehlererkennung, ortsunabhängige Kamerakalibrierung und die Einführung von Beobachtungsredundanz zur Erhöhung der Zuverlässigkeit und Qualitätskontrollverfahren in allen Phasen der photogrammetrischen Datenverarbeitungspipeline, die alle durch strenge, unveränderlich nichtlineare mathematische Modelle gestützt werden (vgl. \cite{vergleich_fraser} S.1-2).

C. Fraser beschreibt den Unterschied zwischen Structure from Motion und Photogrammetrie folgendermaßen \cite{vergleich_fraser}: \\ \\ \textit{ \glqq It could be well argued that a data processing pipeline that is initiated with SfM-based camera localisation, but then follows the principles of photogrammetry, is no-longer SfM per se, but indeed standard photogrammetry. To call a photogrammetry measurement an SfM solution not only implies that the solution is less ‘metric’ (i.e. accurate and reliable) than may be the case, but also attributes more to the SfM process than what is actually there.\grqq }

Structure from Motion ist also ein leistungsstarker Ansatz zur Lösung des Lokalisationsproblems, ausgehend von einer unbekannten Umgebung. Die neu gewonnenen Erkenntnisse hatten dann in der Photogrammetrie wenig Einfluss, da diese schon seit langem ihre eigenen präzisen Algorithmen zur Sensorausrichtung hat. Die Bezeichnungen SLAM, SfM und Photogrammetrie haben also großteils unterschiedliche Bedeutungen, auch wenn es große konzeptionelle und algorithmische Überschneidungen gibt. Weder SLAM noch SfM umfassen den gesamten Prozess der metrischen bildbasierten 3D-Messung, Objektrekonstruktion und Kartierung, welche heute die automatisierte Photogrammetrie auszeichnet (vgl. \cite{vergleich_fraser} S.2).


