\chapter{Photogrammetrie}

\section{Einführung in die Photogrammetrie}

Das Grundprinzip der Messung mit Kameras ist einfach. Licht breitet sich mit einer bestimmten Wellenlänge, in annähernd geraden Strahlen aus. Diese Strahlen werden vom Sensor der Kamera aufgenommen, sodass diese die Richtungen im dreidimensionalen Raum misst. Der grundlegende geometrische Zusammenhang der Photogrammetrie ist somit die Zentralprojektion, die sich mathematisch durch die Kollinearitätsgleichung beschreiben lässt. Ein dreidimensionaler Punkt in der echten Welt, sein Bild in der Kamera und das Projektionszentrum müssen alle auf einer geraden Linie liegen. (vgl. \cite{fiundations_pg} S.1) Das fundamentale photogrammetrische Problem besteht in der Bestimmung von internen und externen Ausrichtungsparametern der Kamera und der  Messung von Objekt und Raumkoordinaten der aufgenommenen Fotografien. 


\begin{itemize}
\item \textbf{Interne Orientierung}: Bei der internen Orientierung werden Kameraparameter gemessen und ausgewertet. Dazu wird die \glqq principle distance\grqq{} (Brennweite) und der \glqq principle point\grqq{} (Optisches Zentrum) betrachtet.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.45]{pp.png}
	\caption{Kamera Kalibierungsmodell, Bildquelle \cite{pp}}
\end{figure} 

Weiterhin müssen Parameter, welche die Verzeichnung, also die nicht maßstabsgetreue Abbildung von Objekten, betrachtet werden. Diese Parameter, die beispielsweise in der Objektivkorrektur verwendet werden, müssen, um die interne Orientierung der Kamera genau abzubilden, mit in die Berechnung einfließen.

\item \textbf{Externe Orientierung}: Bei der externen Orientierung wird versucht die genaue räumliche dreidimensionale Lage der Kamera zum Zeitpunkt der Belichtung des Bildes zu rekonstruieren. Für die Bestimmung der Orientierung von ein oder mehreren Fotos, können verschiedene Methoden verwendet werden. Dies kann in Teilschritten (relative und absolute Orientierung) oder gleichzeitig (Bündelblockausgleich) durchgeführt werden. (vgl. \cite{exterior_review} S.616)
\end{itemize}

Khalid El-AShmawy \cite{comparative_conditions_study} beschreibt die Verwendung von Strahlenbündel, die durch Fotos generiert werden, als zweifelsfrei den flexibelsten Ansatz zur Blockbildung, Blockanpassung und für Photogrammetrie im Allgemeinen und mit den besten Ergebnissen. In der Nahbereichsphotogrammetrie, bei der mehrstufige und konvergente Konfigurationen möglich sind, ist der Bündelansatz in seiner stärksten Form vertreten. 


Der Ausgleich der Strahlenbündel in einem Set an Fotos beinhaltet die Rotation und Translation von jedem Bündel im Raum in eine Position, in der alle Strahlen sich an der korrekten Position im Objektraum schneiden. (vgl. \cite{comparative_conditions_study} S.66)

\section{Bündelblockausgleich}

Das Verfahren des Bündelblockausgeleichs, verwendet die Methoden der \glqq collinearity condition \grqq{} (Kollinearitätsbedingung), der \glqq coplanarity condition\grqq{} (Koplanaritätsbedingung) oder die Methode der direkten linearen Transformation. Die gewünschten Parameter aller Fotos werden gleichzeitig durch eine iterative Wiederholung der \glqq least square\grqq{} Methode (Methode der kleinsten Quadrate) angepasst und korrigiert. Die Iterationen sind durch die nicht-Linearität der Konditionsgleichungen notwendig. Die Resulate des Bündelblockausgleichs aller Fotos sind dann die Ergebnisse der externen Orientierung der Kamera für jedes einzelne Foto. Weiterhin ergibt sich eine Auflistung der Objektraumkoordinaten der gemessenen Punkte aller Fotos, sowie deren gemessene statische Genauigkeit. (vgl. \cite{comparative_conditions_study} S.66-67)

\url{http://sci-hub.tw/https://doi.org/10.3846/20296991.2015.1051335}
\url{http://sci-hub.tw/10.1111/0031-868X.00210}

Neun Elemente:
\url{http://sci-hub.tw/10.1111/phor.12037}

Gutes Paper:
\url{file:///C:/Users/Daniel/Downloads/qu2018msc.pdf}

\section{Nicht-lineare Methode der kleinsten Quadrate}
Die \glqq Method of Least Squares\grqq{} (Methode der kleinsten Quadrate) ist eine sehr leistungsfähige und flexible Technik, um alle Arten von Datenabgleichsproblemen zu lösen. Das Verfahren wird eingesetzt, um eine parametrisierbare Funktion an ein Datenset von Messwerten anzupassen, durch Minimierung der Summe des quadratischen Fehlers zwischen Funktion und Datenpunkten. Die verschiedenen Werkzeuge dieser Methode können auch eingesetzt werden, um beispielsweise die Korrelationsqualität der Messdaten zu bewerten. Gleichzeitig ermöglicht das System die Stabilisierung und Verbesserung der Korrelation, durch die Berücksichtigung geometrischer Randbedingungen. Wenn die anzupassende Funktion nicht linear ist, ist das Problem der kleinsten Quadrate ebenfalls nicht linear. Nichtlineare Lösungen der Methode der kleinsten Quadrate reduzieren iterativ die Summe der quadratischen Fehler zwischen Funktion und Messwerten, durch eine Abfolge von Aktualisierungen der Parameterwerte. (vgl. \cite{least_quares} S.1, \cite{lev_mar} S.1)

In den folgenden Abschnitten werden verschiedene Methoden zur Bestimmung der externen Kameraparameter während des Bündelblockausgleichs vorgestellt. Die Methode der kleinsten Quadrate ist dabei essentiell für die Anwendbarkeit dieser Algorithmen, weswegen diese sowie das Gauss-Newton und das Levenberg-Marquardt Verfahren vorgestellt wird. 

Die nicht lineare Methode der kleinsten Quadrate ist ein Standardoptimierungsproblem und wird definiert als \cite{nonlinear_1} :

\begin{equation}
minimiere: \sum_{i=1}^m f_i(x)^2 =  ||f(x)||^2
\end{equation} 

Wobei: 

$f_1(x),...,f_m(x)$ differenzierbare Funktionen einer Vektorvariablen $x$ sind.

$f$ eine Funktion von $\textbf{R}^n$ zu $\textbf{R}^m$ mit den Komponenten $f_i(x)$ ist:

\begin{equation}
f(x) = \begin{bmatrix}
f_1(x)\\ f_2(x)\\ \cdots \\ f_m(x)
\end{bmatrix}
\end{equation} 

Das Ziel ist es ein $x$ zu finden, dass $||f(x)||^2$ minimiert. In unserem Fall, der Positionsbestimmung von Objekten im Raum mit der Grundlage mehrerer Kamerabilder, kann $f$ folgendermaßen aufgestellt werden:

Das \textbf{Kameramodell} wird beschrieben durch die Parameter: $a \in  \textbf{R}^{2\times 3}, b \in \textbf{R}^2, c \in  \textbf{R}^3, d \in \textbf{R}$ welche die Position und Orientierung charakterisieren. Ein Objekt an Position $x \in \textbf{R}^3 $ erzeugt ein Bild an der Position $x^\prime \in \textbf{R}^2$ auf der Bildebene.

\begin{equation}
x \prime = \frac{1}{c^Tx+d} (Ax +b )
\end{equation}

$c^Tx+d >0$, wenn das Objekt vor der Kamera ist. Angenommen ein Objekt an Position $x_{ex}$ wird von $l$ Kameras betrachtet. (Beschrieben durch $a_i,b_i,c_i,d_i$) Das Bild des Objekts in der Bildebene von Kamera $i$ ist an Position:

\begin{equation}
y_i = \frac{1}{c_i^T x_{ex}+d_i}(A_i x_{ex} + b_i) + v_i
\end{equation}

Wobei $v_i$ der Mess- oder Quantisierungsfehler ist. Das Ziel ist es nun die dreidimensionale Position $e_{ex}$ von den $l$ Beobachtungen $y_1,...,y_l$ zu schätzen. 

\textbf{Nicht-lineare Methode der kleinsten Quadrate:} Berechne die Schätzung von $\hat x$ durch die Minimierung von (vgl. \cite{nonlinear_1} S.5-6):

\begin{equation}
\sum_{i=1}^l || y_i = \frac{1}{c_i^T x_{ex}+d_i}(A_i x_{ex} + b_i) + v_i||²
\end{equation}

\subsection{Gauß-Newton-Verfahren}

Das Gauß-Newton Verfahren ist eine Technik zur Lösung der nicht linearen Methode der kleinsten Quadrate. Das Verfahren besteht aus einer Folge von linearen Annäherungen der kleinsten Quadrate an das nicht lineare Problem, bei dem jedes einzelne durch einen direkten oder iterativen Prozess gelöst wird. (vgl. \cite{approx_gn} S.1) Gegeben ist die Definition der Problemstellung der kleinsten Quadrate, siehe (3.1). Beginnend mit einer anfänglichen Schätzung $x^{(1)}$, werden weitere Näherungslösungen $k = 1,2,...$ berechnet (vgl. \cite{nonlinear_1} S.16-17).

Dazu wird $f$ um $x^{(k)}$ linearisiert:

\begin{equation}
\overline{f}(x;x^{(k)}) = f(x^{(k)})+Df(x^{(k)})(x-x^{(k)})
\end{equation}

Ersetze die affine Annäherung $ \overline{f}(x;x^{(k)})$ für $f$ im Problem der kleinsten Quadrate (3.1):
\begin{equation}
minimiere: ||\overline{f}(x;x^{(k)})||²
\end{equation}

Die Lösung dieses linearen Problems wird nun als $x^{(k+1)}$ verwendet. 

Das Problem der kleinsten Quadrate ist in Wiederholung $k$ des Gauß-Newton Verfahrens gelöst:
\begin{equation}
minimiere: ||f(x^{(k)}) + Df(x^{(k)})(x-x^{(k)})||²
\end{equation}

Wenn $Df(x^{(k)}) $ linear unabhängige Spalten hat, wird die Lösung gegeben durch:
\begin{equation}
x^{k+1} = x^{(k)}-\Big(Df(x^{(k)})^TDf(x^{(k)})\Big)^{-1} Df(x^{(k)})^T f(x^{(k)})
\end{equation}

Der Gauß-Newton Schritt $\Delta x^{(k)} = x^{(k+1)} - x^{(k)}$ ist:
\begin{equation}
\begin{aligned}
\Delta x^{(k)} &= -\Big(Df(x^{(k)})^TDf(x^{(k)})\Big)^{-1} Df(x^{(k)})^T f(x^{(k)})\\ &= -\frac{1}{2} \Big(Df(x^{(k)})^TDf(x^{(k)})\Big)^{-1} \nabla g(x^{(k)})
\end{aligned}
\end{equation}

Wobei $\nabla g(x)$ der Gradient der Kosten für nichtlineare kleinste Quadrate ist.

Das Gauß-Newton Verfahren eignet sich besonders gut für die Verarbeitung von großen Datenmengen mit hoher Varianz. Im Vergleich zum Newton-Verfahren ist der Algorithmus attraktiver, da er keine Auswertung der zweiten Ableitungen in der Hesse-Matrix der Zielfunktion benötigt. (vgl.\cite{approx_gn} S.1, \cite{nonlinear_1} S.16-17)


\subsection{Levenberg-Marquardt Methode}

Die Levenberg-Marquardt Methode wurde 1944 von Kenneth Levenberg \cite{levenberg} veröffentlicht, in den 1960er Jahren von Donald Marquardt wiederentdeckt und wurde entwickelt um nicht lineare Probleme der kleinsten Quadrate zu lösen. Der Algorithmus kombiniert zwei Minimierungsmethoden: \glqq Gradient descent\grqq{} (Gradientenverfahren) und das Gauß-Newton Verfahren. Beim Gradientenverfahren wird die Summe der quadratischen Fehler durch die Aktualisierung der Parameter in Richtung der steilsten Richtung zum Minimum hin reduziert. Das Levenberg-Marquardt Verfahren verhält sich wie das Gradientenverfahren, wenn die Parameter weit von ihrem optimalen Wert entfernt sind und wie das Gauß-Newton Verfahren, wenn die Parameter nahe an ihrem optimalen Wert liegen. Es wechselt also adaptiv die Parameterupdates zwischen den beiden Verfahren. (vgl. \cite{lev_mar} S.1)

Der Algorithmus befasst sich mit zwei Problembereichen des Gauß-Newton Verfahrens:

\begin{itemize}
\item Wie aktualisiert man $x^{(k)}$, wenn die Spalten von $Df(x^{(k)})$ linear Abhängig sind.

\item Wie verfährt man, wenn das Gauß-Newton Update $||f(x)||²$ nicht reduziert.
\end{itemize}

Das Verfahren wird mathematisch wie folgt beschrieben:

Berechnung von $x^{(k+1)}$ durch Lösung eines normalisierten Problems der kleinsten Quadrate:
\begin{equation}
minimiere: ||\overline{f}(x;x^{(k)})||² + \lambda^{(k)}||x-x^{(k)}||²
\end{equation}

$\overline{f}(x;x^{(k)})$ ist dabei wie in Gleichung 3.6 gegeben. Mit $\lambda^{(k)} > 0$ gibt es immer eine eindeutige Lösung.

Das normalisierte Problem der kleinsten Quadrate wird in Iteration $k$ gelöst:
\begin{equation}
minimiere: ||f(x^{(k)}) + Df(x^{(k)})(x-x^{(k)})||² + \lambda^{(k)}||x-x^{(k)}|²
\end{equation}

Die Lösung ist gegeben durch:
\begin{equation}
x^{(k+1)} = x^{(k)} -\Big(Df(x^{(k)})^TDf(x^{(k)})+\lambda^{(k)}I\Big)^{-1} Df(x^{(k)})^T f(x^{(k)})
\end{equation}

Der Levenberg-Marquardt Schritt $\Delta x^{(k)} = x^{(k+1)} - x^{(k)}$ ist:
\begin{equation}
\begin{aligned}
\Delta x^{(k)} &= -\Big(Df(x^{(k)})^TDf(x^{(k)})+\lambda^{(k)}I\Big)^{-1} Df(x^{(k)})^T f(x^{(k)})\\ &= -\frac{1}{2} \Big(Df(x^{(k)})^TDf(x^{(k)})+\lambda^{(k)}I\Big)^{-1} \nabla g(x^{(k)})
\end{aligned}
\end{equation}

Für $\lambda^{(k)}=0$ ist das der Gauß-Newton Schritt; für große $\lambda{(k)}$:
\begin{equation}
\Delta x^{(k)} \approx -\frac{1}{2}\lambda^{(k)}\nabla g(x^{(k)})
\end{equation}

Es gibt verschiedene Strategien um $\lambda^{(k)}$ anzupassen:

\begin{itemize}
\item Nach Iteration $k$, berechne Lösung $\hat{x}$ von Gleichung (3.11)
\item Wenn $||f(\hat{x})||²<||f(x^{(k)})||²$, verwende $x^{(k+1)} = \hat{x}$ und verringere $\lambda$
\item Wenn $||f(\hat{x})||²>||f(x^{(k)})||²$, lasse $x$ gleich (verwende $x^{(k+1)} = x^{(k)}$), und erhöhe $\lambda$
\end{itemize}
(vgl. \cite{nonlinear_1} S.19-21)


\subsection{Bestimmung der externen Kameraparameter mit der Kollinearitätsbedingung}

Die gleichzeitige Anpassung verwendet die Kollinearitätsbedingung  um zwei Gleichungen für jeden gemessenen Bildpunkt aufzustellen. Die Lösung all dieser Gleichungen erfolgt dann nach der Methode der kleinesten Quadrate. Die Bedingung der Kollinearität sagt aus, dass ein Objektpunkt $P$, sein Bildpunkt $p$ und das perspektivische Zentrum $O$, alle auf der gleichen Geraden liegen müssen. Mathematisch wird die Bedingung wie folgt ausgedrückt  \cite{coll_exterior}:

\begin{equation}
\begin{aligned}
  x_p = -f \frac{(X_p-X_O)m_{11}+(Y_p-Y_O)m_{12}+(Z_p-Z_O)m_{13}}{(X_p-X_O)m_{31}+(Y_p-Y_O)m_{32}+(Z_p-Z_O)m_{33}} \\
    y_p = -f \frac{(X_p-X_O)m_{21}+(Y_p-Y_O)m_{22}+(Z_p-Z_O)m_{23}}{(X_p-X_O)m_{31}+(Y_p-Y_O)m_{32}+(Z_p-Z_O)m_{33}}
\end{aligned}
\end{equation}

Dabei sind $x_p$ und $y_p$ die korrigierten Foto Koordinaten, $X_p,Y_p,Z_p$ die Objektpunktkoordinaten von $P$, $X_O,Y_O,Z_O$ die Koordinaten des perspektivischen Zentrums $O$, $f$ die kalibrierte Brennweite der Kamera und $m_{ij}$ die Elemente der Orientierungsmatrix $M$ des Fotos.

Die linearisierte Form der Gleichung, für die Lösung der Methode der kleinsten Quadrate, wird gegeben als (\cite{comparative_conditions_study} S.67):

\begin{equation}
V+B\cdot\triangle =\varepsilon
\end{equation}

Wobei:
\begin{itemize}
\item $\triangle$ der Korrekturvektor zu dem aktuellen Werteset, für die unbekannten Werte (innere und äußere Orientierung, Objektkoordinaten der Punkte) der iterativen Lösung ist.

\item $B$ die Matrix der partiellen Ableitungen von Gleichung (3.1), in Bezug auf die Unbekannten  ist.

\item $V$ der Korrekturvektor zu den Beobachtungen ist.

\item $\varepsilon$ der Abweichungsvektor ist.
\end{itemize}

El-Ashmawy \cite{comparative_conditions_study} schlägt weitere Beschränkungen vor, indem ergänzende Beobachtungsgleichungen berücksichtigt werden, die sich aus den a priori Kenntnissen der Raumkoordinaten der Objekte der Kontrollpunkte in Gleichung (3.2) ergeben. Solche zusätzlichen Gleichungen können wie folgt beschrieben werden:

\begin{equation}
V^c-\triangle^c = \varepsilon^c
\end{equation}

Wobei:

\begin{itemize}
\item $\triangle^c$ der Vektor der beobachtbaren Korrekturen zu den Objektkoordinaten der Kontrollpunkte ist.

\item $\varepsilon^c$ der Abweichungsvektor zwischen Beobachtungswerten und aktuellen (in iterativer Lösung) Werten der Objektkoordinaten der Kontrollpunkte ist.

\end{itemize}

Beobachtungsgleichungen können dann durch das Zusammenführen von Gleichung (3.2) und (3.3) erhalten werden. Die grundlegenden Voraussetzungen an den Bündelblockausgleich sind die Schätzungen der Parameter für innere und äußere Orientierung der Kamera. Weiterhin können die - je nach spezifischem Ansatz - Schätzungen für die Objekt und Raumkoordinaten aller Kontrollpunkte  nützlich sein. Deshalb sollte ein Bündelverfahren immer eine praktikable Methode enthalten, mit der die ungefähren geschätzten initialen Werte ermittelt werden können. Dieses Vorwissen sorgt nicht nur für eine reduzierte Anzahl an Iterationen, sondern resultiert auch in schnelleren und genaueren Ergebnissen. (vgl. \cite{comparative_conditions_study} S.67)


\subsection{Bestimmung der externen Kameraparameter mit der Koplanaritätsbedingung}

Die Koplanaritätsbedingung impliziert, dass die beiden perspektivischen Zentren von zwei Aufnahmen, ein beliebiger Objektpunkt und die entsprechenden Bildpunkte auf den beiden Fotos, alle in einer gemeinsamen Ebene liegen müssen (vgl. Abbildung 3.2). Die Koplanaritätsbedingung kann wie folgt dargestellt werden (\cite{pose_est_epi} S.1204):

\begin{equation}
F_i = \begin{vmatrix}
b_X & b_Y & b_Z \\
X_1 & Y_1 & Z_1 \\
X_2 & Y_2 & Z_2
\end{vmatrix}
=0
\end{equation}

Dabei sind $b_X,b_Y,b_Z$ die Komponenten des Basisvektors $b$ und $X_1,Y_1,Z_1$ sowie $X_2,Y_2,Z_2$ sind die Komponenten des Vektors $\vec{R_1}$ (von $O_1$ zu $P$) respektive  $\vec{R_2}$ (von $O_2$ zu $P$).


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{coplanarity.png}
	\caption{Koplanaritätsbedinung, Bildquelle \cite{comparative_conditions_study}}
\end{figure} 

Das mathematische Modell besteht aus vier skalaren Gleichungen:

\begin{equation}
\begin{aligned}
X_p - (X_{O_1}+0.5(b_X+ \lambda \cdot X_1 + p \cdot X_2)) = 0.0 \\
Y_p - (Y_{O_1}+0.5(b_Y+ \lambda \cdot Y_1 + p \cdot Y_2)) = 0.0 \\
Z_p - (Z_{O_1}+0.5(b_Z+ \lambda \cdot Z_1 + p \cdot Z_2)) = 0.0 \\
D_Y = \lambda\cdot X_1-p\cdot X_2-b_Y = 0.0
\end{aligned}
\end{equation}

Wobei $X_{O_1}, Y_{O_1},Z_{O_1}$ die Objektkoordinaten der ersten Kameraposition während der Belichtung sind und $\lambda$ und $p$ die Skalierungsfaktoren der entsprechenden Positionsvektoren $\vec{r_1}$ und $\vec{r_2}$ im Kameraraum sind. 

Die linearisierte Form von Gleichung (3.5), mit ebenfalls von El-Ashmawy \cite{comparative_conditions_study} vorgeschlagenen zusätzlichen Beschränkungen, für das Verfahren der kleinsten Quadrate, wird gegeben als:

\begin{equation}
\begin{aligned}
A\cdot V + B\cdot \triangle = \varepsilon \\
V^c - \triangle^c = \varepsilon^c
\end{aligned}
\end{equation}


Wobei:
\begin{itemize}
\item $\triangle$ der Korrekturvektor zu dem aktuellen Werteset, für die unbekannten Werte (innere und äußere Orientierung, Objektkoordinaten der Punkte) der iterativen Lösung ist.

\item $A$ die Matrix der partiellen Ableitungen von Gleichung (3.5), in Bezug auf die Beobachtungen (korrigierte Foto-Koordinaten auf den linken und rechten Fotos, des gleichen Objektpunkts) ist.

\item $B$ die Matrix der partiellen Ableitungen von Gleichung (3.5), in Bezug auf die Unbekannten  ist.

\item $V$ der Korrekturvektor zu den Beobachtungen ist.

\item $\varepsilon$ der Abweichungsvektor ist.
\end{itemize}

Zur Verwendung der iterativen Lösung der kleinsten Quadrate, ist die Berechnung der Ausgangswerte von Unbekannten, wie beim Verfahren mit der Kollinearitätsbedinung, notwendig. (vgl. \cite{comparative_conditions_study} S.68)


\subsection{Bestimmung der externen Kameraparameter mit der Direct Linear Transformation Methode}

Das \glqq direkte lineare Transformationsverfahren\grqq{} (DLT) modelliert die Transformation zwischen Bildkoordinatensystem und Objektkoordinatensystem als lineare Funktion und wurde von Abdel-Aziz und Karara \cite{dlt_intro} eingeführt. Die direkte lineare Transformation kann aus den Kollinearitätsgleichungen abgeleitet werden und lassen sich mathematisch wie folgt ausdrücken (\cite{dlt} S.72)

\begin{equation}
\begin{aligned}
x=\frac{L_1X+L_2Y+L_3Z+L4}{L_9X+L_{10}Y+L_{11}Z+1} \\
y=\frac{L_5X+L_6Y+L_7Z+L_8}{L_9X+L_{10}Y+L_{11}Z+1}
\end{aligned}
\end{equation}

Wobei $x,y$ die Bildkoordinaten, $L_1,...,L_{11}$ die Transformationskoeffizienten und $X,Y,Z$ die Objektkoordinaten des Punktes sind. Die Werte der inneren und externen Kameraparameter werden dann berechnet durch:

\begin{equation}
\begin{bmatrix}
X_0 \\ Y_0 \\ Z_0 
\end{bmatrix}
 = -
 \begin{bmatrix}
 L_1 & L_2 & L_3 \\
 L_5 & L_6 & L_7 \\
 L_9 & L_{10} & L_{11}
 \end{bmatrix}^{-1}
 \begin{bmatrix}
 L_4 \\ L_8 \\ 1.0
 \end{bmatrix}
 \end{equation}
 
 \begin{equation}
 \begin{aligned}
 x_0 &= (L_1L_9 + L_2L_{10} + L_3L_{11})/(L²_9 + L²_{10} + L²_{11}); \\
 y_0 &= (L_5L_9 + L_6L_{10} + L_7L_{11})/(L²_9 + L²_{10} + L²_{11}); \\
 \omega &= tan^{-1}(-L_{10}/L_{11}); \\
 \phi &= sin^{-1}(-L_9 \sqrt{(L²_9 + L²_{10} + L²_{11})} \\
  \kappa &= cos^{-1}((x_0L_9 - L_1)/(cos \phi \sqrt{(x_0L_9-L_1)² + (x_0L_{10}-L_2)² + (x_0L_{11}-L_3)²})); \\
 f&=(x_0L_9)/(cos \kappa \cdot \phi \sqrt{L²_9 + L²_{10} + L²_{11}}) 
 \end{aligned}
 \end{equation}

Wobei $X_0,Y_0,Z_0,\omega ,\phi , \kappa $ die externen Kameraparameter, $x_0,y_0$ die Bildkoordinaten des optischen Zentrums und $f$ die Brennweite ist. 

Das direkte lineare Transformationsverfahren hat lange Zeit in den Bereichen Photogrammetrie, Computer Vision, Robotik und Biomechanik Verwendung gefunden. Dies liegt an der linearen Formulierung der Beziehung zwischen Objekt- und Bildkoordinaten. Weiterhin können Bildkoordinaten in einem nicht-orthogonalem System, mit unterschiedlichen Skalen ausgedrückt werden und die Position des Koordinatensystems kann unbekannt, sowie die Brennweite beliebig sein und von Bild zu Bild variieren. (vgl. \cite{dlt} S.72)



\subsection{Feature Matching}

\subsection{Image Matching}

state of art source

\subsection{Structure from Motion}

6.2 Structure from motion

\url{http://sci-hub.tw/https://doi.org/10.1007/s10462-012-9365-8}

\subsection{Depth Maps}

\section{Photogrammetrie für Smartphones}

\section{Evaluierung der photogrammetrischen Technologie für Echtzeit AR Anwendungen}